{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd26e20a",
   "metadata": {},
   "source": [
    "# Statistical and Machine Learning - Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a330b2",
   "metadata": {},
   "source": [
    "#### By - Swasthik Vellingiri Kowsalya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42640818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'nnet' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'neuralnet' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'e1071' was built under R version 3.6.3\"\n",
      "Attaching package: 'e1071'\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    impute\n",
      "\n",
      "\n",
      "Attaching package: 'plotly'\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    last_plot\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    filter\n",
      "\n",
      "The following object is masked from 'package:graphics':\n",
      "\n",
      "    layout\n",
      "\n",
      "Warning message:\n",
      "\"package 'MASS' was built under R version 3.6.3\"\n",
      "Attaching package: 'MASS'\n",
      "\n",
      "The following object is masked from 'package:plotly':\n",
      "\n",
      "    select\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"LiblineaR\")\n",
    "library(LiblineaR)     # LR Lasso (l1)\n",
    "library(mlr)\n",
    "library(nnet)          # class.ind() function\n",
    "library(neuralnet)     # Deep Neural Networks\n",
    "#library(LiblineaR)     # LR Lasso (l1)\n",
    "#library(randomForest)  # Random Forest\n",
    "#library(adabag)        # Boosting\n",
    "library(e1071)         # SVM\n",
    "library(ggplot2)       # Visualization\n",
    "library(plotly)        # 3D visualization\n",
    "library(neuralnet)\n",
    "\n",
    "# Import data\n",
    "library(ISLR)      # Data from the course book\n",
    "library(MASS)      # Boston housing dataset\n",
    "library(datasets)  # US crime dataset\n",
    "\n",
    "# Resize plot\n",
    "library(repr)  # String and binary representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa844197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "96"
      ],
      "text/latex": [
       "96"
      ],
      "text/markdown": [
       "96"
      ],
      "text/plain": [
       "[1] 96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read.csv('C:/Users/svellingirikowsalya/Desktop/Statistical and Machine Learning/SML_Section7/SML_Section7/data/bankruptcy_prediction/data.csv')\n",
    "ncol(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b14e4",
   "metadata": {},
   "source": [
    "## Q1: Randomly divide data into train/test as 80/20 ( set.seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "045f2a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf5563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split1 = sample(c(rep(0, 0.8 * nrow(df)), rep(1, 0.2 * nrow(df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "622fde60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train <- df[split1 == 0, ]\n",
    "data_test <- df[split1 == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65a2cc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1364</li>\n",
       "\t<li>96</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1364\n",
       "\\item 96\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1364\n",
       "2. 96\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1364   96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36b72a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5455</li>\n",
       "\t<li>96</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5455\n",
       "\\item 96\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5455\n",
       "2. 96\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5455   96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d4ecb",
   "metadata": {},
   "source": [
    "## Q2: Build a NN model with 1 hidden layer of 30 neurons, sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c3886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hidden: 30    thresh: 0.01    rep: 1/2    steps:       8\terror: 92.49689\ttime: 0.16 secs\n",
      "hidden: 30    thresh: 0.01    rep: 2/2    steps:      14\terror: 92.49176\ttime: 0.3 secs\n"
     ]
    }
   ],
   "source": [
    "nn_md1 <- neuralnet(Bankrupt.~.,          # The formula\n",
    "                     data_train,             # Training data\n",
    "                     hidden=c(30),      # Size of the hidden layers\n",
    "                     #threshold=0.1,          # Stopping criteria, a.k.a convergence\n",
    "                     stepmax=5000,            # Maximum training step\n",
    "                     rep=2,                  # Number of training repeat, a.k.a epoch\n",
    "                     lifesign='full',         # Print training process\n",
    "                     lifesign.step=5000,      # Print out every 5000 steps\n",
    "                     algorithm='rprop+',      # Algorithm to calculate the network, 'rprop+'=resilient backpropagation\n",
    "                     learningrate=0.01,       # Learning rate, only use for traditional backpropagation\n",
    "                     err.fct='sse',           # Error function, sse=sum square error, ce=cross-entropy\n",
    "                     act.fct=\"logistic\",      # Activation function, 'logistic' or 'tanh'\n",
    "                     linear.output=F\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06722de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.966086159486709"
      ],
      "text/latex": [
       "0.966086159486709"
      ],
      "text/markdown": [
       "0.966086159486709"
      ],
      "text/plain": [
       "[1] 0.9660862"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction and evaluation on train\n",
    "\n",
    "y_train_pred <- predict(nn_md1, data_train[, c(2:96)])\n",
    "mean((max.col(y_train_pred)-1) == data_train$Bankrupt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "360b0903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.974340175953079"
      ],
      "text/latex": [
       "0.974340175953079"
      ],
      "text/markdown": [
       "0.974340175953079"
      ],
      "text/plain": [
       "[1] 0.9743402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction and evaluation on test\n",
    "y_test_pred <- predict(nn_md1, data_test[, c(2:96)])\n",
    "mean((max.col(y_test_pred)-1) == data_test$Bankrupt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ff409",
   "metadata": {},
   "source": [
    "## Q3: Build a deep NN model with multiple hidden layers (of your choice) and sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c4a19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hidden: 10, 10, 10, 10    thresh: 0.01    rep: 1/3    steps:     294\terror: 88.55562\ttime: 7.16 secs\n",
      "hidden: 10, 10, 10, 10    thresh: 0.01    rep: 2/3    steps:      64\terror: 89.31346\ttime: 1.5 secs\n",
      "hidden: 10, 10, 10, 10    thresh: 0.01    rep: 3/3    steps:      29\terror: 89.35688\ttime: 0.79 secs\n"
     ]
    }
   ],
   "source": [
    "nn_md2 <- neuralnet(Bankrupt.~.,          # The formula\n",
    "                     data_train,             # Training data\n",
    "                     hidden=c(10,10,10,10),      # Size of the hidden layers\n",
    "                     #threshold=0.1,          # Stopping criteria, a.k.a convergence\n",
    "                     stepmax=10000,            # Maximum training step\n",
    "                     rep=3,                  # Number of training repeat, a.k.a epoch\n",
    "                     lifesign='full',         # Print training process\n",
    "                     lifesign.step=5000,      # Print out every 5000 steps\n",
    "                     algorithm='rprop+',      # Algorithm to calculate the network, 'rprop+'=resilient backpropagation\n",
    "                     learningrate=0.01,       # Learning rate, only use for traditional backpropagation\n",
    "                     err.fct='sse',           # Error function, sse=sum square error, ce=cross-entropy\n",
    "                     act.fct=\"logistic\",      # Activation function, 'logistic' or 'tanh'\n",
    "                     linear.output=F\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "75d0d0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.966086159486709"
      ],
      "text/latex": [
       "0.966086159486709"
      ],
      "text/markdown": [
       "0.966086159486709"
      ],
      "text/plain": [
       "[1] 0.9660862"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction and evaluation on train\n",
    "\n",
    "y_train_pred <- predict(nn_md2, data_train[, c(2:96)])\n",
    "mean((max.col(y_train_pred)-1) == data_train$Bankrupt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7adf2a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.974340175953079"
      ],
      "text/latex": [
       "0.974340175953079"
      ],
      "text/markdown": [
       "0.974340175953079"
      ],
      "text/plain": [
       "[1] 0.9743402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction and evaluation on test\n",
    "y_test_pred <- predict(nn_md2, data_test[, c(2:96)])\n",
    "mean((max.col(y_test_pred)-1) == data_test$Bankrupt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb623a",
   "metadata": {},
   "source": [
    "## Q4: Build 5 other classification models and compare with the 2 previous NN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d136c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ML classification task\n",
    "\n",
    "train_task <- mlr::makeClassifTask(id ='MNIST_train', data=data_train, target='Bankrupt.')\n",
    "test_task <- mlr::makeClassifTask(id='MNIST_test', data=data_test, target='Bankrupt.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "479d5145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Lasso (l1)\n",
    "learner <- mlr::makeLearner('classif.LiblineaRL1LogReg')  # Register a machine learning model\n",
    "model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task, proba=T)\n",
    "lasso = performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a5ae774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Nearest Neighbor (k=50)\n",
    "learner <- makeLearner('classif.knn', k=50)\n",
    "model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task)\n",
    "knn = performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1293733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA (drop zero-variance features)\n",
    "learner <- makeLearner('classif.lda')\n",
    "model <- mlr::train(learner, filterFeatures(train_task, method='variance', threshold=0.1))\n",
    "#model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task)\n",
    "lda = performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e179b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "learner <- mlr::makeLearner('classif.rpart')  # Register a machine learning model\n",
    "model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task)\n",
    "DT = performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa76714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "learner <- makeLearner('classif.svm', scale=FALSE, kernel='linear')  # linear,polynomial,radial,sigmoid\n",
    "model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task)\n",
    "svm = performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f882204c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Models</th><th scope=col>Age</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>NN_train      </td><td>0.9660862     </td></tr>\n",
       "\t<tr><td>NN_test       </td><td>0.9743402     </td></tr>\n",
       "\t<tr><td>Lasso_reg     </td><td>0.9743402     </td></tr>\n",
       "\t<tr><td>KNN           </td><td>0.9743402     </td></tr>\n",
       "\t<tr><td>LDA           </td><td>0.9706745     </td></tr>\n",
       "\t<tr><td>Decision_trees</td><td>0.9714076     </td></tr>\n",
       "\t<tr><td>SVM           </td><td>0.5821114     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Models & Age\\\\\n",
       "\\hline\n",
       "\t NN\\_train       & 0.9660862       \\\\\n",
       "\t NN\\_test        & 0.9743402       \\\\\n",
       "\t Lasso\\_reg      & 0.9743402       \\\\\n",
       "\t KNN            & 0.9743402     \\\\\n",
       "\t LDA            & 0.9706745     \\\\\n",
       "\t Decision\\_trees & 0.9714076       \\\\\n",
       "\t SVM            & 0.5821114     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Models | Age |\n",
       "|---|---|\n",
       "| NN_train       | 0.9660862      |\n",
       "| NN_test        | 0.9743402      |\n",
       "| Lasso_reg      | 0.9743402      |\n",
       "| KNN            | 0.9743402      |\n",
       "| LDA            | 0.9706745      |\n",
       "| Decision_trees | 0.9714076      |\n",
       "| SVM            | 0.5821114      |\n",
       "\n"
      ],
      "text/plain": [
       "  Models         Age      \n",
       "1 NN_train       0.9660862\n",
       "2 NN_test        0.9743402\n",
       "3 Lasso_reg      0.9743402\n",
       "4 KNN            0.9743402\n",
       "5 LDA            0.9706745\n",
       "6 Decision_trees 0.9714076\n",
       "7 SVM            0.5821114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comaparison\n",
    "\n",
    "# Both the neural Network models gave the same accuracy and hence only one result is included in the final table\n",
    " \n",
    "Models <- c('NN_train','NN_test','Lasso_reg', 'KNN', 'LDA', 'Decision_trees','SVM')\n",
    "Accuracy <- c(mean((max.col(y_train_pred)-1) == data_train$Bankrupt.),mean((max.col(y_test_pred)-1) == data_test$Bankrupt.),lasso, knn, lda, DT,svm)\n",
    "\n",
    "df <- data.frame(Models, Age)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51167c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
